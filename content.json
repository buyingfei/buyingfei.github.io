{"meta":{"title":"陌上花开，缓缓归兮","subtitle":"天行健，君子以自强不息；地势坤，君子以厚德载物.","description":null,"author":"buyingfei","url":"http://yoursite.com"},"pages":[{"title":"about","date":"2018-05-03T07:36:00.000Z","updated":"2018-05-07T03:20:54.024Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":""}],"posts":[{"title":"系统监控之sysstat 命令","slug":"sysstatcmd","date":"2018-05-24T14:49:08.000Z","updated":"2018-05-23T12:48:40.181Z","comments":true,"path":"2018/05/24/sysstatcmd/","link":"","permalink":"http://yoursite.com/2018/05/24/sysstatcmd/","excerpt":"","text":"sysstat 工具简介sysstat 是 Linux 系统中的常用工具包。在使用 Linux 系统时，常常会遇到各种各样的问题，比如系统容易死机或者运行速度突然变慢，这时我们常常猜测：是否硬盘空间不足，是否内存不足，是否 I/O 出现瓶颈，还是系统的核心参数出了问题？这时，我们应该考虑使用 sysstat 工具对系统做一个全面了解，分析系统的负载状况。 sysstat 安装12345sudo yum -y install sysstat# 安装成功后，会生成这个文件[/etc/cron.d/sysstat ] 定时生成系统统计信息# sudo cat /etc/cron.d/sysstat# 默认是每10 分钟生成一次，开发环境修改为每一分钟生成一次统计信息 # 默认生成日志文件路径[cd /var/log/sa] 图示如下： 输出进程队列长度和平均负载状态统计信息1234567891011121314151617181920212223#输出进程队列长度和平均负载状态统计信息 [root@172.16.0.56:/var/log/sa]$ sar -q Linux 2.6.32-431.el6.x86_64 (node56) 05/23/2018 _x86_64_ (2 CPU) #系统正常运行实例 12:00:01 AM runq-sz plist-sz ldavg-1 ldavg-5 ldavg-15 12:10:01 AM 26 339 0.19 0.88 1.11 12:20:01 AM 27 333 0.57 1.02 1.10 12:30:01 AM 30 345 0.81 0.87 0.98 12:40:01 AM 26 340 0.07 0.44 0.75 12:50:01 AM 28 331 0.05 0.21 0.49 01:00:01 AM 32 359 0.12 0.13 0.32 01:10:01 AM 25 344 0.06 0.08 0.18 # 系统异常运行实例 08:14:01 PM runq-sz plist-sz ldavg-1 ldavg-5 ldavg-15 08:15:01 PM 0 233 5.84 4.86 2.13 08:16:01 PM 0 233 2.14 3.97 1.99 08:17:03 PM 0 245 3.00 3.82 2.06 08:18:01 PM 0 245 7.54 4.97 2.56 08:19:01 PM 0 246 9.47 5.97 3.05 08:20:01 PM 0 233 9.74 6.82 3.53 08:21:01 PM 0 233 3.58 5.57 3.31 08:22:01 PM 0 233 1.31 4.56 3.10 输出项说明： Tables Are runq-sz 等待执行的任务队列长度，越长越阻塞 plist-sz 进程列表中进程（processes）和线程（threads）的数量 ldavg-1 最后1分钟的系统平均负载（System load average） ldavg-5 过去5分钟的系统平均负载 ldavg-15 过去15分钟的系统平均负载 重点注意ldavg，代表 cpu 任务数，繁重程度,超过cpu 个数，为超负载运行 （注意观察负载变化是否剧烈） 输出CPU使用情况的统计信息12345678910111213141516171819202122[root@172.16.0.56:/var/log/sa]$ sar -uLinux 2.6.32-431.el6.x86_64 (node56) 05/23/2018 _x86_64_ (2 CPU)#系统正常运行实例12:00:01 AM CPU %user %nice %system %iowait %steal %idle12:10:01 AM all 1.66 0.00 0.89 0.08 0.01 97.3612:20:01 AM all 1.56 0.00 0.81 0.07 0.01 97.5512:30:01 AM all 1.58 0.00 0.84 0.35 0.01 97.2112:40:01 AM all 1.57 0.00 0.82 0.06 0.01 97.5412:50:01 AM all 1.57 0.00 0.82 0.05 0.01 97.5401:00:01 AM all 1.56 0.00 0.82 0.05 0.01 97.5501:10:01 AM all 1.64 0.00 0.86 0.14 0.01 97.35#系统异常运行实例08:14:01 PM CPU %user %nice %system %iowait %steal %idle08:15:01 PM all 0.25 0.00 1.21 31.99 0.00 66.5508:16:01 PM all 0.27 0.00 0.71 0.59 0.00 98.4408:17:03 PM all 0.43 0.00 7.97 78.37 0.00 13.2308:18:01 PM all 0.18 0.00 4.14 95.68 0.00 0.0008:19:01 PM all 0.40 0.00 4.48 95.12 0.00 0.0008:20:01 PM all 0.22 0.00 3.84 89.52 0.00 6.4108:21:01 PM all 0.27 0.00 0.87 0.49 0.00 98.37 输出项说明： cpu all 表示统计信息为所有 CPU 的平均值。 %user 显示在用户级别(application)运行使用 CPU 总时间的百分比。 %nice 显示在用户级别，用于nice操作，所占用 CPU 总时间的百分比。 %system 在核心级别(kernel)运行所使用 CPU 总时间的百分比。 %iowait cpu 等待io占用 CPU 总时间的百分比。（值越高，等待磁盘读写压力越大，瓶颈在磁盘） %steal 管理进程等待cpu 占用 CPU 总时间的百分比。（值越高，cpu 繁重程度越高） %idle 显示 CPU 空闲时间占用 CPU 总时间的百分比。 若 %iowait 的值过高，表示硬盘存在I/O瓶颈 若 %idle 的值高但系统响应慢时，有可能是 CPU 等待分配内存，此时应加大内存容量 若 %idle 的值持续低于 10，则系统的 CPU 处理能力相对较低，表明系统中最需要解决的资源是 CPU。 输出内存和交换空间的统计信息12345678910111213141516171819202122[root@172.16.0.56:/var/log/sa]$ sar -rLinux 2.6.32-431.el6.x86_64 (node56) 05/23/2018 _x86_64_ (2 CPU)#系统正常08:14:01 PM kbmemfree kbmemused %memused kbbuffers kbcached kbcommit %commit08:15:01 PM 1073412 833500 43.71 167416 96632 1192820 30.2908:16:01 PM 1072668 834244 43.75 167572 97032 1192960 30.2908:17:03 PM 1037000 869912 45.62 167188 140820 1355556 34.4208:18:01 PM 1037396 869516 45.60 167220 140856 1355556 34.4208:19:01 PM 1035992 870920 45.67 167352 141992 1355556 34.4208:20:01 PM 1087212 819700 42.99 167372 94096 1192960 30.2908:21:01 PM 1086880 820032 43.00 167432 94460 1193108 30.29#系统异常12:00:01 AM kbmemfree kbmemused %memused kbbuffers kbcached kbcommit %commit12:10:01 AM 560300 3362440 85.72 636624 1060076 3352040 27.2312:20:01 AM 537124 3385616 86.31 636836 1079920 3378996 27.4512:30:01 AM 513536 3409204 86.91 637044 1096120 3410272 27.7012:40:01 AM 511468 3411272 86.96 637204 1103256 3357232 27.2712:50:01 AM 488416 3434324 87.55 637340 1124880 3389172 27.5301:00:01 AM 457144 3465596 88.35 637556 1134900 3407764 27.68 输出项说明： cpu all 表示统计信息为所有 CPU 的平均值。 kbmemfree 可用的空闲内存数量，单位为 KB kbmemused 已使用的内存数量（不包含内核使用的内存），单位为 KB %memused 已使用内存的百分数 kbbuffers 磁盘块缓存的内存数量，单位为 KB kbcached 磁盘文件缓存的内存数量，单位为 KB kbcached 程序要执行下去，系统评估还需要多少缓存的内存数量，单位为 KB 如果 %memused + %commit &gt; 100% ,内存很危险 物理内存放硬盘 情况12345678910111213[root@172.16.0.56:/var/log/sa]$ sar -BLinux 2.6.32-431.el6.x86_64 (node56) 05/23/2018 _x86_64_ (2 CPU)12:00:01 AM pgpgin/s pgpgout/s fault/s majflt/s pgfree/s pgscank/s pgscand/s pgsteal/s %vmeff12:10:01 AM 0.29 138.03 5137.86 0.01 2500.29 0.00 0.00 0.00 0.0012:20:01 AM 0.45 136.06 4935.45 0.01 2409.97 0.00 0.11 0.11 100.0012:30:01 AM 0.13 135.86 5002.52 0.01 2419.22 0.00 0.05 0.05 100.0012:40:01 AM 0.09 135.66 5012.26 0.01 2436.21 0.00 0.11 0.11 100.0012:50:01 AM 0.00 135.86 4938.99 0.00 2416.47 0.00 0.11 0.11 100.0001:00:01 AM 0.00 136.01 5057.40 0.00 2445.28 0.00 0.11 0.11 100.0001:10:01 AM 0.49 145.58 5024.75 0.01 2445.67 0.00 0.00 0.00 0.0001:20:02 AM 0.00 137.24 4969.16 0.00 2430.44 0.00 0.16 0.16 98.9601:30:01 AM 0.00 136.91 4989.06 0.00 2403.75 0.00 0.11 输出项说明： table col pgpgin/s 每秒钟从磁盘读入的系统页面的 KB 总数 pgpgout/s 每秒钟向磁盘写出的系统页面的 KB 总数 fault/s 系统每秒产生的页面失效(major + minor)数量 majflt/s 系统每秒产生的页面失效(major)数量 显示I/O和传送速率的统计信息1234567891011[root@172.16.0.56:/var/log/sa]$ sar -bLinux 2.6.32-431.el6.x86_64 (node56) 05/23/2018 _x86_64_ (2 CPU)12:00:01 AM tps rtps wtps bread/s bwrtn/s12:10:01 AM 5.62 0.04 5.59 0.59 276.0512:20:01 AM 5.45 0.04 5.41 0.91 272.1212:30:01 AM 5.48 0.02 5.46 0.25 271.7312:40:01 AM 5.44 0.02 5.42 0.19 271.3112:50:01 AM 5.35 0.00 5.35 0.00 271.7201:00:01 AM 5.44 0.00 5.44 0.00 272.0201:10:01 AM 5.95 0.08 5.88 0.99 291.15 输出项说明： table col tps 每秒钟 物理设备请求次数 rtps 每秒从物理设备读入请求次数 wtps 每秒向物理设备写入请求次 bread/s 每秒从物理设备读入请求次数，单位为 块/s bwrtn/s 每秒向物理设备写入请求次，单位为 块/s","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://yoursite.com/categories/操作系统/"}],"tags":[{"name":"测试 sysstat 系统监控","slug":"测试-sysstat-系统监控","permalink":"http://yoursite.com/tags/测试-sysstat-系统监控/"}],"keywords":[{"name":"操作系统","slug":"操作系统","permalink":"http://yoursite.com/categories/操作系统/"}]},{"title":"系统监控之top 命令","slug":"topcmd","date":"2018-05-23T09:42:05.000Z","updated":"2018-05-23T10:05:09.930Z","comments":true,"path":"2018/05/23/topcmd/","link":"","permalink":"http://yoursite.com/2018/05/23/topcmd/","excerpt":"","text":"TOP命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况。可以根据top 命令初步判断系统发生问题下面是对top 命令一些常用操作进行归总，方便分析系统问题结果图示：默认以cpu 占用率倒序排列 进程各字段含义：在top 命令在，按F 或者f 得到如下 得到帮助在top 命令在，按 h 得到如下 根据内存使用情况倒序排列在top 命令在，按O后，按n，得到如下图示 结果如下 将当前所有系统进程，按内存占用情况倒序排列1top -ab -n 1","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://yoursite.com/categories/操作系统/"}],"tags":[{"name":"测试 top 系统监控","slug":"测试-top-系统监控","permalink":"http://yoursite.com/tags/测试-top-系统监控/"}],"keywords":[{"name":"操作系统","slug":"操作系统","permalink":"http://yoursite.com/categories/操作系统/"}]},{"title":"压力测试 之io 测试","slug":"fiocmd","date":"2018-05-21T12:49:08.000Z","updated":"2018-05-23T12:48:40.365Z","comments":true,"path":"2018/05/21/fiocmd/","link":"","permalink":"http://yoursite.com/2018/05/21/fiocmd/","excerpt":"","text":"fio 工具简介Linux系统上采用fio工具来对硬盘进行的IO测试。 sysstat 安装1sudo yum -y install fio 123456789101112131415161718192021可以使用fio -help查看每个参数，具体的参数左右可以在官网查看how to文档，如下为几个常见的参数描述filename=/tmp/fio 支持文件系统或者裸设备，-filename=/dev/sda2或-filename=/dev/sdbdirect=1 测试过程绕过机器自带的buffer，使测试结果更真实rw=randwread 测试随机读的I/Orw=randwrite 测试随机写的I/Orw=randrw 测试随机混合写和读的I/Orw=read 测试顺序读的I/Orw=write 测试顺序写的I/Orw=rw 测试顺序混合写和读的I/Obs=4k 单次io的块文件大小为4kbsrange=512-2048 同上，提定数据块的大小范围size=5g 本次的测试文件大小为5g，以每次4k的io进行测试numjobs=30 本次的测试线程为30runtime=1000 测试时间为1000秒，如果不写则一直将5g文件分4k每次写完为止ioengine=psync io引擎使用pync方式，如果要使用libaio引擎，需要yum install libaio-devel包rwmixwrite=30 在混合读写的模式下，写占30%group_reporting 关于显示结果的，汇总每个进程的信息此外lockmem=1g 只使用1g内存进行测试zero_buffers 用0初始化系统buffernrfiles=8 每个进程生成文件的数量 fio测试场景及生成报告详解1234567891011121314#100%随机，100%读， 4Kfio -filename=/tmp/fio -direct=1 -iodepth 1 -thread -rw=randread -ioengine=psync -bs=4k -size=1000G -numjobs=10 -runtime=30 -group_reporting -name=fiotest#100%随机，100%写， 4Kfio -filename=/tmp/fio -direct=1 -iodepth 1 -thread -rw=randwrite -ioengine=psync -bs=4k -size=1000G -numjobs=10 -runtime=30 -group_reporting -name=fiotest#100%顺序，100%读 ，4Kfio -filename=/tmp/fio -direct=1 -iodepth 1 -thread -rw=read -ioengine=psync -bs=4k -size=1000G -numjobs=10 -runtime=30 -group_reporting -name=fiotest#100%顺序，100%写 ，4Kfio -filename=/tmp/fio -direct=1 -iodepth 1 -thread -rw=write -ioengine=psync -bs=4k -size=1000G -numjobs=10 -runtime=30 -group_reporting -name=fiotest#100%随机，70%读，30%写 4Kfio -filename=/tmp/fio -direct=1 -iodepth 1 -thread -rw=randrw -rwmixread=70 -ioengine=psync -bs=4k -size=1000G -numjobs=10 -runtime=30 -group_reporting -name=fiotest 运行一下命令，进行分析1fio -filename=/tmp/fio -direct=1 -iodepth 1 -thread -rw=randrw -rwmixread=70 -ioengine=psync -bs=4k -size=1000G -numjobs=10 -runtime=30 -group_reporting -name=fiotest 结果图示： 1234567891011121314151617181920212223242526272829io=执行了多少M的IObw=平均IO带宽iops=IOPSrunt=线程运行时间slat=提交延迟clat=完成延迟lat=响应时间bw=带宽cpu=利用率IO depths=io队列IO submit=单个IO提交要提交的IO数IO complete=Like the above submit number, but for completions instead.IO issued=The number of read/write requests issued, and how many of them were short.IO latencies=IO完延迟的分布io=总共执行了多少size的IOaggrb=group总带宽minb=最小.平均带宽.maxb=最大平均带宽.mint=group中线程的最短运行时间.maxt=group中线程的最长运行时间.ios=所有group总共执行的IO数.merge=总共发生的IO合并数.ticks=Number of ticks we kept the disk busy.io_queue=花费在队列上的总共时间.util=磁盘利用率","categories":[{"name":"压力测试","slug":"压力测试","permalink":"http://yoursite.com/categories/压力测试/"}],"tags":[{"name":"测试 fio 系统监控","slug":"测试-fio-系统监控","permalink":"http://yoursite.com/tags/测试-fio-系统监控/"}],"keywords":[{"name":"压力测试","slug":"压力测试","permalink":"http://yoursite.com/categories/压力测试/"}]},{"title":"乐观锁及其实现","slug":"optimismlock","date":"2018-05-15T06:36:06.000Z","updated":"2018-05-16T06:55:26.478Z","comments":true,"path":"2018/05/15/optimismlock/","link":"","permalink":"http://yoursite.com/2018/05/15/optimismlock/","excerpt":"","text":"为什么需要锁（并发控制）？在多用户环境中，在同一时间可能会有多个用户更新相同的记录，这会产生冲突。这就是著名的并发性问题。 典型的冲突 丢失更新：一个事务的更新覆盖了其它事务的更新结果，就是所谓的更新丢失。例如：用户A把值从6改为2，用户B把值从2改为6，则用户A丢失了他的更新。 脏读：当一个事务读取其它完成一半事务的记录时，就会发生脏读取。例如：用户A,B看到的值都是6，用户B把值改为2，用户A读到的值仍为6。 为了解决这些并发带来的问题。 我们需要引入并发控制机制。 并发控制机制 悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。 乐观锁：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。 乐观锁不能解决脏读的问题。 乐观锁假设认为数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则让返回用户错误的信息，让用户决定如何去做。 在对数据库进行处理的时候，乐观锁并不会使用数据库提供的锁机制。一般的实现乐观锁的方式就是记录数据版本。 数据版本,为数据增加的一个版本标识。当读取数据时，将版本标识的值一同读出，数据每更新一次， 同时对版本标识进行更新。 当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第一次取出来的版本标识进行比对， 如果数据库表当前版本号与第一次取出来的版本标识值相等， 则予以更新，否则认为是过期数据。 实现数据版本有两种方式，第一种是使用版本号，第二种是使用时间戳。 使用版本号实现乐观锁 使用版本号时，可以在数据初始化时指定一个版本号，每次对数据的更新操作都对版本号执行+1操作。并判断当前版本号是不是该数据的最新的版本号。 12345671.查询出商品信息select (status,status,version) from t_goods where id=#&#123;id&#125;2.根据商品信息生成订单3.修改商品status为2update t_goods set status=2,version=version+1where id=#&#123;id&#125; and version=#&#123;version&#125;; 库表设计 12345678CREATE TABLE `goods` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(20) DEFAULT NULL COMMENT &apos;名称&apos;, `status` tinyint(4) DEFAULT &apos;0&apos; COMMENT &apos;0 未下单；1 已下单&apos;, `cnt` int(11) DEFAULT NULL COMMENT &apos;商品数量&apos;, `version` int(11) DEFAULT &apos;1&apos; COMMENT &apos;版本号&apos;, PRIMARY KEY (`id`) ) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8mb4 golang 代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package mainimport ( \"database/sql\" _ \"github.com/go-sql-driver/mysql\" \"fmt\" \"strconv\")var db, err = sql.Open(\"mysql\", \"buyf:123456@tcp(192.168.132.128:3306)/tmpdb?charset=utf8\") //第一个参数为驱动名func checkErr(err error) &#123; if err != nil &#123; panic(err) &#125;&#125;func getGoodsById(id int) (int,int) &#123; var cnt,version int err := db.QueryRow(\"select cnt,version from goods where id = ?\", id).Scan(&amp;cnt, &amp;version) checkErr(err) return cnt,version&#125;func printGoodsInfo(id int,cnt int,version int) &#123; // int to string string() // string(int num) 为空 fmt.Println(\"商品编号： \"+ strconv.Itoa(id) + \" 当前库存：\"+ strconv.Itoa(cnt) + \" 当前版本：\"+ strconv.Itoa(version))&#125;func modifyGoodsNum(id int,version int) bool &#123; cnt,_ := getGoodsById(id) if cnt &lt;= 0 &#123; fmt.Println(\"商品编号： \"+ strconv.Itoa(id) + \"数量小于1，不能下单\") return false &#125; stmt, err := db.Prepare(`update goods set cnt = cnt -1 ,version = version + 1 where id = ? and version = ? `) checkErr(err) res, err := stmt.Exec(id, version) checkErr(err) num, err := res.RowsAffected() checkErr(err) if num &lt;= 0 &#123; return false &#125; return true&#125;func main() &#123; checkErr(err) var cnt1,version1 = getGoodsById(1) printGoodsInfo(1,cnt1,version1) var cnt2,version2 = getGoodsById(1) printGoodsInfo(1,cnt2,version2) // 修改需要传入版本号，实际过程中，可以加入事务，进行提交和回滚 if modifyGoodsNum(1,version1) &#123; fmt.Println(\"乐观锁 操作成功\") &#125; if !modifyGoodsNum(1,version2) &#123; fmt.Println(\"乐观锁 操作失败\") &#125;&#125; 参考链接：深入理解乐观锁与悲观锁乐观锁与悲观锁——解决并发问题","categories":[{"name":"golang","slug":"golang","permalink":"http://yoursite.com/categories/golang/"},{"name":"数据库","slug":"golang/数据库","permalink":"http://yoursite.com/categories/golang/数据库/"}],"tags":[{"name":"golang mysql","slug":"golang-mysql","permalink":"http://yoursite.com/tags/golang-mysql/"}],"keywords":[{"name":"golang","slug":"golang","permalink":"http://yoursite.com/categories/golang/"},{"name":"数据库","slug":"golang/数据库","permalink":"http://yoursite.com/categories/golang/数据库/"}]},{"title":"简单 golang 接口限流","slug":"limitqps","date":"2018-05-11T07:49:13.000Z","updated":"2018-05-11T08:04:57.408Z","comments":true,"path":"2018/05/11/limitqps/","link":"","permalink":"http://yoursite.com/2018/05/11/limitqps/","excerpt":"","text":"曾经在一个大神的博客里看到这样一句话：在开发高并发系统时，有三把利器用来保护系统：缓存、降级和限流。那么何为限流呢？顾名思义，限流就是限制流量，就像你宽带包了1个G的流量，用完了就没了。通过限流，我们可以很好地控制系统的qps，从而达到保护系统的目的。本篇文章将会介绍一下计数器限流算法并用golang 实现。 计数器法 计数器法是限流算法里最简单也是最容易实现的一种算法。比如我们规定，对于A接口来说，我们1分钟的访问次数不能超过100个。那么我们可以这么做：在一开始的时候，我们可以设置一个计数器counter，每当一个请求过来的时候，counter就加1，如果counter的值大于100并且该请求与第一个请求的间隔时间还在1分钟之内，那么说明请求数过多；如果该请求与第一个请求的间隔时间大于1分钟，且counter的值还在限流范围内，那么就重置counter，具体算法的示意图如下： 伪代码 如下：123456789101112131415161718192021public class CounterDemo &#123; public long timeStamp = getNowTime(); public int reqCount = 0; public final int limit = 100; // 时间窗口内最大请求数 public final long interval = 1000; // 时间窗口ms public boolean grant() &#123; long now = getNowTime(); if (now &lt; timeStamp + interval) &#123; // 在时间窗口内 reqCount++; // 判断当前时间窗口内是否超过最大请求控制数 return reqCount &lt;= limit; &#125; else &#123; timeStamp = now; // 超时后重置 reqCount = 1; return true; &#125; &#125;&#125; 实现代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293package mainimport ( \"fmt\" \"io\" \"net/http\" \"sync\" \"time\" \"strings\")type RequestLimitStruct struct &#123; RequestCnt map[string] int Lock sync.Mutex&#125;type RequestLimitService struct &#123; Interval time.Duration MaxCount int RequestLimit RequestLimitStruct&#125;func NewRequestLimitService(interval time.Duration, maxCnt int) *RequestLimitService &#123; reqLimit := &amp;RequestLimitService&#123; Interval: interval, MaxCount: maxCnt, &#125; reqLimit.RequestLimit.RequestCnt = make(map[string]int) go func() &#123; ticker := time.NewTicker(interval) for &#123; &lt;-ticker.C reqLimit.RequestLimit.Lock.Lock() fmt.Println(\"Reset Count...\") for key,_ := range reqLimit.RequestLimit.RequestCnt &#123; reqLimit.RequestLimit.RequestCnt[key] = 0 &#125; reqLimit.RequestLimit.Lock.Unlock() &#125; &#125;() return reqLimit&#125;func (reqLimit *RequestLimitService) Increase(r *http.Request) &#123; reqLimit.RequestLimit.Lock.Lock() defer reqLimit.RequestLimit.Lock.Unlock() remoteIP := strings.Split(r.RemoteAddr, \":\")[0] requestUri := r.RequestURI key := remoteIP + string(':') + requestUri if v, exists := reqLimit.RequestLimit.RequestCnt[key]; exists &#123; reqLimit.RequestLimit.RequestCnt[key] = v + 1 &#125; else &#123; reqLimit.RequestLimit.RequestCnt[key] = 1 &#125; fmt.Println(\"请求\" + key + \" \" + string(reqLimit.RequestLimit.RequestCnt[key]))&#125;func (reqLimit *RequestLimitService) IsAvailable(r *http.Request) bool &#123; remoteIP := strings.Split(r.RemoteAddr, \":\")[0] requestUri := r.RequestURI key := remoteIP + string(':') + requestUri reqLimit.RequestLimit.Lock.Lock() defer reqLimit.RequestLimit.Lock.Unlock() if v, exists := reqLimit.RequestLimit.RequestCnt[key]; exists &#123; reqLimit.RequestLimit.RequestCnt[key] = v + 1 &#125; return reqLimit.RequestLimit.RequestCnt[key] &lt; reqLimit.MaxCount&#125;var RequestLimit = NewRequestLimitService(10*time.Second, 5)func HttpHander(w http.ResponseWriter, r *http.Request) &#123; remoteIP := strings.Split(r.RemoteAddr, \":\")[0] requestUri := r.RequestURI key := remoteIP + string(':') + requestUri if RequestLimit.IsAvailable(r) &#123; RequestLimit.Increase(r) fmt.Println(RequestLimit.RequestLimit.RequestCnt[key]) io.WriteString(w, \"Hello world!\\n\") &#125; else &#123; fmt.Println(\"Reach request limiting!\") io.WriteString(w, \"Reach request limit!\\n\") &#125;&#125;func main() &#123; fmt.Println(\"Server Started!\") http.HandleFunc(\"/\", HttpHander) http.ListenAndServe(\":8000\", nil)&#125; 发送请求：1seq 100 | xargs -P10 -I% curl localhost:8000 相应结果：","categories":[{"name":"golang","slug":"golang","permalink":"http://yoursite.com/categories/golang/"}],"tags":[{"name":"限制流量 golang 高并发","slug":"限制流量-golang-高并发","permalink":"http://yoursite.com/tags/限制流量-golang-高并发/"}],"keywords":[{"name":"golang","slug":"golang","permalink":"http://yoursite.com/categories/golang/"}]},{"title":"tcpdump 抓包及Wireshark 解析包实例","slug":"crawlerpacket","date":"2018-05-07T02:17:45.000Z","updated":"2018-05-07T09:04:19.660Z","comments":true,"path":"2018/05/07/crawlerpacket/","link":"","permalink":"http://yoursite.com/2018/05/07/crawlerpacket/","excerpt":"","text":"生产服务器使用nginx代理转发，开发环境和测试环境（没有nginx 代理转发其他服务器）都已通过测试，此时抓包进行分析数据流，进而排查问题。 场景：负责客服系统 –（电呼模块）客服需要知道当前有多少用户在打电话排队，此时有2 种解决方案，一种是轮询，一种就是保持长链，轮询会小号比较大资源，时效性也逊色于长链，所有技术选型为采用长链方式，即采用websocket + swoole。 安全分析：不开放websocket 端口对外，访问swoole服务，需要请求nginx 对外开放端口 即nginx server 模块中 listen 对应值，然后nginx 做代理转发，转发到swoole 服务对应端口。 生产环境模拟：线上使用nginx 反向代理，即我们请求uri 先发送给前端nginx 代理服务器，再有此代理服务器转发给实际应用所在服务器。开发过程中，没有反向代理，服务正常运行，到线上链接不上服务器，此时采用抓包分析线上问题。 此时自己开发机器[192.168.132.128]作为代理机，测试服务器[172.16.0.56] 作为服务机，模拟线上场景 自己开发机器[192.168.132.128]nginx 配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116upstream websocket &#123; server 127.0.0.1:9501;&#125;upstream globalWebsocket &#123; # 转发到测试机 server 172.16.0.56:9588;&#125;map $http_upgrade $connection_upgrade &#123; default upgrade; '' close;&#125;server &#123; listen 12345; #listen [::]:80; server_name tickets.2345.com ; charset utf-8; index index.html index.htm index.php default.html default.htm default.php; root /home/buyf/quest/backend/web; #include /home/buyf/quest.2345.com/backend/web.conf; #error_page 404 /404.html; # Deny access to PHP files in specific directory #location ~ /(wp-content|uploads|wp-includes|images)/.*\\.php$ &#123; deny all; &#125; location = /tickets &#123; rewrite .* /index.html last; &#125; location = /tickets/ &#123; rewrite .* /index.html last; &#125; location ~ /tickets &#123; rewrite ^/tickets(/.*) $1 last; &#125; location / &#123; client_max_body_size 1000m; set $new_uri $uri; add_header Access-Control-Allow-Origin '*'; add_header Access-Control-Allow-Methods 'GET,POST,OPTIONS'; try_files $uri $uri/ /index.php?$query_string; &#125; #location = /tickets/websocket &#123; # proxy_pass ws://tickets.2345.com:9501 ; #&#125; location ~ /appManage(/.*) &#123; set $root_path appManage; root /opt/case/dkwapp.2345.com/dkwapp/web; set $new_uri $1; try_files $1 $1/ /index.php?$query_string; &#125; location ~ /websocket &#123; proxy_pass http://websocket; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \"Upgrade\"; &#125; location ~ /globalWebsocket &#123; # proxy_pass http://tickets.2345.com:9588; proxy_pass http://globalWebsocket; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \"Upgrade\"; &#125; #include enable-php.conf; location ~ \\.php$ &#123; fastcgi_pass unix:/tmp/php-cgi.sock; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; fastcgi_param REQUEST_URI $new_uri; fastcgi_intercept_errors off; fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; &#125; location ~ .*\\.(gif|jpg|jpeg|png|bmp|swf)$ &#123; add_header Access-Control-Allow-Origin 'http://tickets.2345.com:8090'; add_header Access-Control-Allow-Methods 'GET,POST,OPTIONS'; expires 30d; &#125; location ~ .*\\.(js|css|json)?$ &#123; expires 12h; &#125; location ~ /.well-known &#123; allow all; &#125; location ~ /\\. &#123; deny all; &#125; access_log /home/wwwlogs/quest.2345.com.access.log; error_log /home/wwwlogs/quest.2345.com.error.log notice; &#125; 服务机[172.16.0.56] nginx 配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100upstream websocket &#123; server 127.0.0.1:9501;&#125;upstream globalWebsocket &#123; # 转发到本机9588 端口 server 127.0.0.1:9588;&#125;log_format post '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent $request_time $upstream_response_time \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\" body: $request_body';server &#123; listen 12345; server_name quest.2345.com 172.16.0.56 www.waptianqi.com; index index.html index.htm index.php; access_log logs/quest.2345.com_access.log main; error_log logs/quest.2345.com_error.log notice; set $next_root /opt/case/quest.2345.com/backend/web; charset utf-8; if ($request_uri ~ '/appManage') &#123; set $next_root /opt/case/dkwapp.2345.com/web; &#125; root $next_root; location = /appManage &#123; rewrite .* /index.html last; &#125; location = /appManage/ &#123; rewrite .* /index.html last; &#125; location = /appManage/index.html &#123; rewrite .* /index.html last; &#125; location /appManage &#123; rewrite ^/appManage(/.*) $1 last; &#125; location = /tickets &#123; rewrite .* /index.html last; &#125; location = /tickets/ &#123; rewrite .* /index.html last; &#125; location = /tickets/index.html &#123; rewrite .* /index.html last; &#125; location /tickets &#123; rewrite ^/tickets(/.*) $1 last; &#125; # websocket location = /websocket &#123; proxy_pass http://websocket; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \"Upgrade\"; proxy_read_timeout 3600s; &#125; location ~ /globalWebsocket &#123; proxy_pass http://globalWebsocket; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \"Upgrade\"; &#125; location / &#123; set $new_uri $uri; try_files $uri $uri/ /index.php?$query_string; &#125; location ~ \\.php$ &#123; fastcgi_pass 127.0.0.1:9002; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; fastcgi_param REQUEST_URI $new_uri; if ($request_method = 'POST') &#123; access_log logs/quest.2345.com_access.log post; &#125; # 开发使用 fastcgi_intercept_errors off; fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; &#125;&#125; 进行对9588 websocket 端口进行抓包1sudo tcpdump -i eth0 port 9588 -w /tmp/buyf.cap 使用Wireshark 进行网络分析通过返回值、tcp流、http流可以分析出整个通信过程。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://yoursite.com/categories/操作系统/"}],"tags":[{"name":"网络抓包","slug":"网络抓包","permalink":"http://yoursite.com/tags/网络抓包/"}],"keywords":[{"name":"操作系统","slug":"操作系统","permalink":"http://yoursite.com/categories/操作系统/"}]},{"title":"hexo 初体验","slug":"hexo-1","date":"2018-05-03T08:24:07.000Z","updated":"2018-05-07T03:20:54.024Z","comments":true,"path":"2018/05/03/hexo-1/","link":"","permalink":"http://yoursite.com/2018/05/03/hexo-1/","excerpt":"","text":"为什么选择hexo ？之前php 版本个人博客，放在新浪sae上，更新不频繁，长时间不使用，被新浪收回资源，就想有没有免费、自己不需要维护相关服务的那？就觉得hexo 尝试下吧 有哪些优点那： 支持Markdown 不需要维护服务器，长时间不使用，不担心数据丢失，网站挂掉 快速、简洁、高效，迅速利用靓丽的主题生成静态网页 hexo 存在一个问题，安装好之后，如果更换电脑怎么办那？也是有办法的，在github 个人博客分支下，新建dev 分支，将hexo 生成文件都存放到dev 分支下，之后只需要安装好git、node 、hexo 就行具体hexo 安装参考 hexo 官方文档","categories":[{"name":"web开发","slug":"web开发","permalink":"http://yoursite.com/categories/web开发/"}],"tags":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/tags/前端/"}],"keywords":[{"name":"web开发","slug":"web开发","permalink":"http://yoursite.com/categories/web开发/"}]}]}